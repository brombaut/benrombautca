<h1 id="trees-and-graphs">Trees and Graphs</h1>
<h2 id="trees">Trees</h2>
<p>We’ll discuss trees first and then graphs, even though trees are
really just a type of graph</p>
<h3 id="types-of-trees">Types of Trees</h3>
<p>A nice way to understand a tree is with a recursive explanation. A
tree is a data structure composed of nodes.</p>
<ul>
<li>Each tree has a root node.</li>
<li>The root node has zero or more child nodes.</li>
<li>Each child node has zero or more childe nodes, and so on.</li>
</ul>
<p>A tree cannot contain cycles. The nodes may or may not be in a
particular order, they could have any data type as values, and they may
or may not have links back to their parent nodes.</p>
<p>A very simple class definition for <code>Node</code> is:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Node:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.children <span class="op">=</span> <span class="bu">list</span>()</span></code></pre></div>
<p>You might also have a <code>Tree</code> class to wrap this node.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Tree:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, root):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.root: Node <span class="op">=</span> root</span></code></pre></div>
<h4 id="trees-vs.-binary-trees">Trees vs. Binary Trees</h4>
<p>A binary tree is a tree in which each node has up to two children.
Not all trees are binary trees. For example, this tree is not a binary
tree. You could call it a ternary tree.</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/00_ternary_tree.png" /></p>
<p>There are occasions when you might have a tree that is not a binary
tree. For example, suppose you were using a tree to represent a bunch of
phone numbers. In this case, you might use a 10-ary tree, with each node
having up to 10 children (one for each digit).</p>
<p>A node is called a “leaf” node if it has no children.</p>
<h4 id="binary-tree-vs-binary-search-tree">Binary Tree vs Binary Search
Tree</h4>
<p>A binary search tree is a binary tree in which every node fits a
specific ordering property: <strong>all left descendents &lt;= n &lt;
all right descendents</strong>. This must be true for each node n.</p>
<p>Note that this inequality must be true for all of a node’s
descendents, not just its immediate children.</p>
<p>A binary search tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/01_binary_search_tree.png" /></p>
<p>Not a binary search tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/02_not_binary_search_tree.png" /></p>
<p>A binary search tree imposes the condition that, for each node, its
left descendents are less than or equal to the current node, which is
less than the right descendents.</p>
<h4 id="balanced-vs.-unbalanced">Balanced vs. Unbalanced</h4>
<p>While many trees are balanced, not all are. Note that balancing a
tree does not mean the left and right subtrees are exactly the same size
(like you see under “perfect binary trees” below).</p>
<p>One way to think about it is that a “balanced” tree really means
something more like “not terribly imbalanced”. It’s balanced enought to
ensure <code>O(log n)</code> times for <code>insert</code> and
<code>find</code>, but it’s not necessarily as balanced as it could
be.</p>
<h4 id="complete-binary-trees">Complete Binary Trees</h4>
<p>A complete binary tree is a binary tree in which every level of the
tree is fully filled, except for perhaps the last level. To the extent
that the last level is filled, it is filled left to right.</p>
<p>Not a complete binary tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/03_not_complete_binary_tree.png" /></p>
<p>A complete binary tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/04_complete_binary_tree.png" /></p>
<h4 id="full-binary-trees">Full Binary Trees</h4>
<p>A full binary tree is a binary tree in which every node has either
zero or two children. That is, no nodes have only one child.</p>
<p>Not a full binary tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/05_not_full_binary_tree.png" /></p>
<p>A full binary tree:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/06_full_binary_tree.png" /></p>
<h4 id="perfect-binary-trees">Perfect Binary Trees</h4>
<p>A perfect binary tree is one that is both full and complete. All leaf
nodes will be at the same level, and the level has the maximum number of
nodes.</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/07_perfect_binary_tree.png" /></p>
<p>Note that perfect trees are rare, as a perfect tree must have exactly
<span class="math inline">2<sup><em>k</em></sup> − 1</span> nodes (where
<span class="math inline"><em>k</em></span> is the number of
levels).</p>
<h3 id="binary-tree-traversal">Binary Tree Traversal</h3>
<h4 id="in-order-traversal">In-Order Traversal</h4>
<p>In-order traversal means to “visit” (often, print) the left branch,
then the current node, then the right branch.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> in_order_traversal(node):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> node <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.left)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    visit(node)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.right)</span></code></pre></div>
<p>When performed on a binary search tree, it visits the nodes in
ascending order (hence the name “in-order”).</p>
<h4 id="pre-order-traversal">Pre-Order Traversal</h4>
<p>Pre-order traversal visits the current node before its child nodes
(hence the name “pre-order”).</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> in_order_traversal(node):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> node <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    visit(node)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.left)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.right)</span></code></pre></div>
<p>In a pre-order traversal, the root is always the first node
visited.</p>
<h4 id="post-order-traversal">Post-Order Traversal</h4>
<p>Post-order traversal visits the current node after its child nodes
(hence the name “post-order”).</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> in_order_traversal(node):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> node <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.left)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    in_order_traversal(node.right)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    visit(node)</span></code></pre></div>
<p>In a post-order traversal, the root is always the last node
visited.</p>
<h3 id="binary-heaps-min-heaps-and-max-heaps">Binary Heaps (Min-Heaps
and Max-Heaps)</h3>
<p>We’ll only discuss min-heaps here. Max-heaps are essentially
equivalent, but the elements are in descending order rather than
ascending order.</p>
<p>A min-heap is a <em>complete</em> binary tree (that is, totally
filled other than the rightmost elements on the last level) where each
node is smaller than its children. The root, therefore, it the minimum
element in the tree.</p>
<p>For example:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/08_min_heap.png" /></p>
<p>We have two key operations on a min-heap: <code>insert</code> and
<code>extract_min</code>.</p>
<p><code>Insert</code></p>
<p>When we insert into a min-heap, we always start by inserting the
element at the bottom. We insert at the rightmost spot so as to maintain
the complete tree property.</p>
<p>Then, we “fix” the tree by swapping the new element with its parent,
until we find an appropriate spot for the element. We essentially bubble
up the minimum element.</p>
<ul>
<li>Step 1: Insert 2</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/09_min_heap_insert_1.png" /></p>
<ul>
<li>Step 2: Swap 2 and 7</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/10_min_heap_insert_2.png" /></p>
<ul>
<li>Step 3: Swap 2 and 4</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/11_min_heap_insert_3.png" /></p>
<p>This take <code>O(log n)</code> time, where <code>n</code> is the
number of nodes in the heap.</p>
<p><code>Extract Minimum Element</code></p>
<p>Finding the minimum element of a min-heap is easy: it’s always at the
top. The trickier part is how to remove it (in fact, this isn’t that
tricky).</p>
<p>First, we remove the minimum element and swap it with the last
element in the heap (the bottommost rightnost element). Then, we bubble
down this element, swapping it with one of its children until the
min-heap property is restored.</p>
<p>Do we swap it with the left child or the right child? This depends on
their values. There’s no inherent ordering between the left and right
element, but you’ll need to take the smaller one in order to maintain
the min-heap ordering.</p>
<ul>
<li>Step 1: Replace min with 80</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/12_min_heap_remove_min_1.png" /></p>
<ul>
<li>Step 2: Swap 23 and 80</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/13_min_heap_remove_min_2.png" /></p>
<ul>
<li>Step 3: Swap 32 and 80</li>
</ul>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/14_min_heap_remove_min_3.png" /></p>
<p>This algorithm will take <code>O(log n)</code> time.</p>
<h3 id="tries-prefix-trees">Tries (Prefix Trees)</h3>
<p>A trie (sometimes called a prefix tree) is a funny data structure. A
trie is a variant of an n-ary tree in which characters are stored at
each node. Each path down the tree may represent a word.</p>
<p>The <code>*</code> nodes (sometimes called “null nodes”) are often
used to indicate complete words. For example, the fact that there is a
<code>*</code> node under <code>MANY</code> indicates that
<code>MANY</code> is a complete word. The existence of the
<code>MA</code> path indicates there are words that start with
<code>MA</code>.</p>
<p>The actual implementation of these <code>*</code> nodes might be a
special type of child (such as a <code>TerminatingTrieNode</code>, which
inherits from <code>TrieNode</code>). Or, we could use just a boolean
flat <code>terminates</code> within the “parent” node.</p>
<p>A node in a trie could have anywhere from <code>0</code> to
<code>ALPHABET_SIZE + 1</code> children.</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/15_prefix_trees.png" /></p>
<p>Very commonly, a trie us used to store the entire (English) language
for quick prefix lookups. While a hash table can quickly look up where a
string is a valid word, it cannot tell us if a string is a prefix of any
valid words. A trie can do this very quickly.</p>
<p>How quickly? A trie can check is a string is a valid prefix in
<code>O(K)</code> time, where <code>K</code> is the length of the
string. This is actually the same runtime as a hash table will take.
Although we often refer to has table lookups as being <code>O(1)</code>
time, this isn’t entirely true. A hash table must read through all the
characters in the input, which take <code>O(K)</code> time in the case
of a word lookup.</p>
<p>Many problems involving lists of valid words leverage a trie as an
optimization. In situations when we search through the tree on related
prefixes repeatedly (e.g., looking up <code>M</code>, then
<code>MA</code>, then <code>MAN</code>, the <code>MANY</code>), we might
pass around a reference to the current node in the tree. This will allow
us to just check if <code>Y</code> is a child of <code>MAN</code>,
rather than starting from the root each time.</p>
<h2 id="graphs">Graphs</h2>
<p>A tree is actually a type of graph, but not all graphs are trees.
Simply put, a tree is a connected graph without cycles.</p>
<p>A graph is simply a collection of nodes with edges between (some of)
them</p>
<ul>
<li>Graphs can be either directed (like the following graph) or
undirected. While directed edges are like a one-way street, undirected
edges are like a two-way street.</li>
<li>The graph might consist of multiple isolated subgraphs. If there is
a path between every pair of vertices, it is called a “connected
graph”.</li>
<li>Teh graph can also have cycles (or not). An “acyclic graph” is one
without cycles.</li>
</ul>
<p>Visually, you could draw a graph like this:</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/16_graph_directed_example.png" /></p>
<p>In terms of programming, there are two common ways to represent a
graph.</p>
<h3 id="adjacency-list">Adjacency List</h3>
<p>This is the most common way to represent a graph. Every vertex (or
node) stores a list of adjacent vertices. In an undirected graph, an
edge like <code>(a, b)</code> would be stored twice: once in
<code>a</code>’s adjacent vertices and once in <code>b</code>’s adjacent
vertices.</p>
<p>A simple class definition for a graph node could look essentially the
same as a tree node.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Graph <span class="op">{</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">public</span> <span class="bu">Node</span><span class="op">[]</span> Nodes<span class="op">;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> <span class="bu">Node</span> <span class="op">{</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">public</span> <span class="bu">String</span> name<span class="op">;</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">public</span> <span class="bu">Node</span><span class="op">[]</span> children<span class="op">;</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>The <code>Graph</code> class is used because, unlike in a tree, you
can’t necessarily reach all the nodes from a single node.</p>
<p>You don’t necessarily need any additional classes to represent a
graph. An array (or a hash table) of lists (arrays, arraylists, linked
lists, etc.) can store the adjacency list. The graph above could be
represented as:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span>: <span class="dv">1</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>: <span class="dv">2</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>: <span class="dv">0</span>, <span class="dv">3</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>: <span class="dv">2</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>: <span class="dv">6</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>: <span class="dv">4</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>: <span class="dv">5</span></span></code></pre></div>
<p>This is a bit more compact, but it isn’t quite as clean. We tend to
use node classes unless there’s a compelling reason not to.</p>
<h3 id="adjacency-matrices">Adjacency Matrices</h3>
<p>An adjacency matrix is an NxN boolean matrix (where N is the number
of nodes), where a <code>true</code> value at <code>matrix[i][j]</code>
indicates an edge from node <code>i</code> to node <code>j</code>. (You
can also use an integer matrix with 0s and 1s).</p>
<p>In an undirected graph, an adjacency matrix will be symmetrics. In a
directed graph, it will not (necessarily) be.</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/17_adjacency_matrix_graph.png" /></p>
<table>
<thead>
<tr>
<th></th>
<th><strong>0</strong></th>
<th><strong>1</strong></th>
<th><strong>2</strong></th>
<th><strong>3</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0</strong></td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>The same graph algorithms that are used on adjacency lists
(breadth-first search, etc.) can be performed with adjacency matrices,
but they may be somewhat less efficient. In the same adjacency list
representation, you can easily iterate through the neighbors of a node.
In the adjacency matrix representation, you will need to iterate through
all the nodes to identify a node’s neighbors.</p>
<h3 id="graph-search">Graph Search</h3>
<p>The two most common ways to search a graph are depth-first search and
breadth-first search.</p>
<p>In depth-first search (DFS), we start at the root (or another
arbitrarily selected node) and explore each branch completly before
moving on to the next branch. That is, we go deep first (hence the name
<em>depth-first</em> search) before we got wide.</p>
<p>In breadth-first search (BFS), we start a the root (or another
arbitrarily selected node) and explore each neighbor before going on to
any of their children. That is, we got wide (hence the name
<em>breadth-first</em> search) before we got deep.</p>
<p>See the below depiction of a graph and its depth-first and
breadth-first search (assuming neighbors are iterated in numerical
order).</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/18_graph_search_graph.png" /></p>
<h4 id="depth-first-search">Depth-First Search</h4>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>:  Node <span class="dv">0</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>:    Node <span class="dv">1</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>:      Node <span class="dv">3</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>:        Node <span class="dv">2</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>:        Node <span class="dv">4</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>:  Node <span class="dv">5</span></span></code></pre></div>
<h4 id="breadth-first-search">Breadth-First Search</h4>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>:  Node <span class="dv">0</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>:  Node <span class="dv">1</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>:  Node <span class="dv">4</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>:  Node <span class="dv">5</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>:  Node <span class="dv">3</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>:  Node <span class="dv">2</span></span></code></pre></div>
<p>Breadth-first search and depth-first search tend to be used in
different scenarios. DFS is often preferred if we want to visit every
node in the graph. Both will work just fine, but depth-first search is a
bit simpler.</p>
<p>However, if we want to find the shortest path (or just any path)
between two nodes, BFS is generally better. Consider representing all
the friendships in the entire world in a graph and trying to find a path
of frienships between <code>Ash</code> and <code>Vanessa</code>.</p>
<p>In depth-first search, we could take a path like
<code>Ash -&gt; Brian -&gt; Carleton -&gt; Davis -&gt; Eric -&gt; Farah -&gt; Gayle -&gt; Harry -&gt; Isabella -&gt; John -&gt; Kari...</code>
and then find ourselves very far away. We could go through most of the
world without realizing that, in fact, <code>Vanessa</code> is
<code>Ash</code>’s friend. We will still eventually find the path, but
it may take a long time. It also won’t find us the shortest path.</p>
<p>In breadth-first search, we would stay close to <code>Ash</code> for
as long as possible. We might iterate through many of <code>Ash</code>’s
friends, but we wouldn’t go to his more distance connections until
absolutly necessary. If <code>Vanessa</code> is <code>Ash</code>’s
friend, or his friend-of-a-friend, we’ll find this out relatively
quickly.</p>
<h5 id="depth-first-search-dfs">Depth-First Search (DFS)</h5>
<p>In DFS, we visit a node <code>a</code> and the iterate through each
of <code>a</code>’s neighbors. When visiting a node <code>b</code> that
is a neighbor of <code>a</code>, we visit all of <code>b</code>’s
neighbors before going on to <code>a</code>’s other neighbors. That is,
<code>a</code> exhaustively searches <code>b</code>’s branch before any
of its other neighbors.</p>
<p>Note that pre-order and other forms of tree traversal are a form of
DFS. The key difference is that when implementing this algorithm for a
graph, we must check if the node has been visited. If we don’t we risk
getting stuck in an infinite loop.</p>
<p>The pseudocode below implements DFS:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> <span class="fu">search</span> <span class="op">(</span><span class="bu">Node</span> root<span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="op">(</span>root <span class="op">==</span> <span class="kw">null</span><span class="op">)</span> <span class="cf">return</span><span class="op">;</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">visit</span><span class="op">(</span>root<span class="op">);</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  root<span class="op">.</span><span class="fu">visited</span> <span class="op">=</span> <span class="kw">true</span><span class="op">;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">foreach</span> <span class="op">(</span><span class="bu">Node</span> n in root<span class="op">.</span><span class="fu">adjacent</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>n<span class="op">.</span><span class="fu">visited</span> <span class="op">==</span> <span class="kw">false</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">search</span><span class="op">(</span>n<span class="op">)</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<h5 id="breadth-first-search-dfs">Breadth-First Search (DFS)</h5>
<p>BFS is a bit less intuitive. The main tripping point is the false
assumption that BFS is recursive. It’s not. Instead, it uses a
queue.</p>
<p>In BFS, node <code>a</code> visits each of <code>a</code>’s neighbors
before visiting any of <em>their</em> neighbors. You can think of this
as searching level by level out from <code>a</code>. An interative
solution involving a queue usually works best.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> <span class="fu">search</span><span class="op">(</span><span class="bu">Node</span> root<span class="op">)</span> <span class="op">{</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">Queue</span> queue <span class="op">=</span> <span class="kw">new</span> <span class="bu">Queue</span><span class="op">();</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  root<span class="op">.</span><span class="fu">marked</span> <span class="op">=</span> <span class="kw">true</span><span class="op">;</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  queue<span class="op">.</span><span class="fu">enqueue</span><span class="op">(</span>root<span class="op">);</span> <span class="co">// Add to the end of queue</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> <span class="op">(!</span>queue<span class="op">.</span><span class="fu">isEmpty</span><span class="op">())</span> <span class="op">{</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">Node</span> r  <span class="op">=</span> queue<span class="op">.</span><span class="fu">dequeue</span><span class="op">();</span> <span class="co">// Remove from the front of the queue</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">visit</span><span class="op">(</span>r<span class="op">);</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">foreach</span> <span class="op">(</span><span class="bu">Node</span> n in r<span class="op">.</span><span class="fu">adjacent</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>      n<span class="op">.</span><span class="fu">marked</span> <span class="op">=</span> <span class="kw">true</span><span class="op">;</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>      queue<span class="op">.</span><span class="fu">enqueue</span><span class="op">(</span>n<span class="op">);</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Always remember for BFS that you use a queue.</p>
<h5 id="bidirectional-search">Bidirectional Search</h5>
<p>Bidirectional search is used to find the shortest path between a
source and destination. It operates by essentially running two
simultaneous breadth-first searches, one from each node. When their
searches collide, we have found a path.</p>
<p><strong>Breadth-First Search</strong> Single search from
<code>s</code> to <code>t</code> that collides after four levels.</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/19_bfs_graph.png" /></p>
<p><strong>Bidirectional Search</strong> Two searches (one from
<code>s</code> and one from <code>t</code>) that collide after four
levels total (two levels each).</p>
<p><img
src="https://raw.githubusercontent.com/brombaut/articles-authored/main/assets/images/trees_and_graphs/20_bidirectional_search_graph.png" /></p>
<p>To see why this is faster, consider a graph where every node has at
most <span class="math inline"><em>k</em></span> adjacent nodes and the
shortest path from node <span class="math inline"><em>s</em></span> to
node <span class="math inline"><em>t</em></span> has length <span
class="math inline"><em>d</em></span>.</p>
<ul>
<li>In traditional breadth-first search, we would search up to <span
class="math inline"><em>k</em></span> nodes in the first “level” of the
search. In the second level, we would search up to <span
class="math inline"><em>k</em></span> nodes for each of those first
<span class="math inline"><em>k</em></span> nodes, so <span
class="math inline"><em>k</em><sup>2</sup></span> nodes total (thus
far). We would do this <span class="math inline"><em>d</em></span>
times, so that’s <span
class="math inline"><em>O</em>(<em>k</em><sup><em>d</em></sup>)</span>.</li>
<li>In bidirectional search, we have two searches that collide after
approximately <span class="math inline"><em>d</em>/2</span> levels (the
midpoint of the path). The search from <span
class="math inline"><em>s</em></span> visits approximately <span
class="math inline"><em>k</em><sup><em>d</em>/2</sup></span>, as does
the search from <span class="math inline"><em>t</em></span>. That’s
approximately <span
class="math inline">2 * <em>k</em><sup><em>d</em>/2</sup></span>, or
<span
class="math inline"><em>O</em>(<em>k</em><sup><em>d</em>/2</sup>)</span>,
nodes total.</li>
</ul>
<p>This might seem like a minor difference, but it’s not. It’s huge.
Recall that <span
class="math inline">(<em>k</em><sup><em>d</em>/2</sup>) * (<em>k</em><sup><em>d</em>/2</sup>) = <em>k</em><sup><em>d</em></sup></span>.
The bidirectional search is actually faster by a factor of <span
class="math inline"><em>k</em><sup><em>d</em>/2</sup></span>.</p>
<p>Put another way: if our system could only support searching “friend
of friend” paths in breadth-first search, it could now likely support
“friend of friend of friend of friend” paths. We can support paths that
are twice as long.</p>
