<h1 id="simple-mnist-neural-net-from-scratch">Simple MNIST Neural Net
from scratch</h1>
<p>Here we implemented a simple two-layer neural network and trained it
on the MNIST digit recognizer dataset. It’s meant to be an instructional
example, through which you can understand the underlying math of neural
networks better.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span></code></pre></div>
<p>Get the dataset</p>
<p>Once you download and save the dataset, you can just reload them
using the commented code</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">&quot;mnist_784&quot;</span>, version<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>mnist[<span class="st">&#39;data&#39;</span>].to_csv(<span class="st">&#39;./mnist_data.csv&#39;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>mnist[<span class="st">&#39;target&#39;</span>].to_csv(<span class="st">&#39;./mnist_target.csv&#39;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mnist.keys()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># mnist = dict()</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># mnist[&#39;data&#39;] = pd.read_csv(&#39;./mnist_data.csv&#39;, index_col=0)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># mnist[&#39;target&#39;] = pd.read_csv(&#39;./mnist_target.csv&#39;, index_col=0).squeeze(&#39;columns&#39;)</span></span></code></pre></div>
<p>Preprocess the data so it’s in a format we want (Numpy arrays) and
shuffle into dev and train sets</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data, target <span class="op">=</span> mnist[<span class="st">&quot;data&quot;</span>].to_numpy(), mnist[<span class="st">&quot;target&quot;</span>].to_numpy()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> target.astype(np.uint8)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.c_[target, data]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.astype(np.uint8)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>m, n <span class="op">=</span> data.shape</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>np.random.shuffle(data)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>data_dev <span class="op">=</span> data[<span class="dv">0</span>:<span class="dv">1000</span>].T</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>Y_dev <span class="op">=</span> data_dev[<span class="dv">0</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>X_dev <span class="op">=</span> data_dev[<span class="dv">1</span>:n]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>X_dev <span class="op">=</span> X_dev <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>data_train <span class="op">=</span> data[<span class="dv">1000</span>:m].T</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>Y_train <span class="op">=</span> data_train[<span class="dv">0</span>]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> data_train[<span class="dv">1</span>:n]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>_, m_train <span class="op">=</span> X_train.shape</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Y_train)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train[:, <span class="dv">0</span>].shape)</span></code></pre></div>
<pre><code>[8 1 5 ... 4 2 3]
(784,)</code></pre>
<p>Our NN will have a simple two-layer architecture. Input layer <span
class="math inline"><em>a</em><sup>[0]</sup></span> will have 784 units
corresponding to the 784 pixels in each 28x28 input image. A hidden
layer <span class="math inline"><em>a</em><sup>[1]</sup></span> will
have 10 units with ReLU activation, and finally our output layer <span
class="math inline"><em>a</em><sup>[2]</sup></span> will have 10 units
corresponding to the ten digit classes with softmax activation.</p>
<h3 id="forward-propagation">Forward propagation</h3>
<p><span
class="math display"><em>Z</em><sup>[1]</sup> = <em>W</em><sup>[1]</sup><em>X</em> + <em>b</em><sup>[1]</sup></span></p>
<p><span
class="math display"><em>A</em><sup>[1]</sup> = <em>g</em><sub>ReLU</sub>(<em>Z</em><sup>[1]</sup>)</span></p>
<p><span
class="math display"><em>Z</em><sup>[2]</sup> = <em>W</em><sup>[2]</sup><em>A</em><sup>[1]</sup> + <em>b</em><sup>[2]</sup></span></p>
<p><span
class="math display"><em>A</em><sup>[2]</sup> = <em>g</em><sub>softmax</sub>(<em>Z</em><sup>[2]</sup>)</span></p>
<h3 id="backward-propagation">Backward propagation</h3>
<p><span
class="math display"><em>d</em><em>Z</em><sup>[2]</sup> = <em>A</em><sup>[2]</sup> − <em>Y</em></span></p>
<p><span
class="math display"><em>d</em><em>W</em><sup>[2]</sup> = (1/<em>m</em>)<em>d</em><em>Z</em><sup>[2]</sup><em>A</em><sup>[1]<em>T</em></sup></span></p>
<p><span
class="math display"><em>d</em><em>B</em><sup>[2]</sup> = (1/<em>m</em>)<em>Σ</em><em>d</em><em>Z</em><sup>[2]</sup></span></p>
<p><span
class="math display"><em>d</em><em>Z</em><sup>[1]</sup> = <em>W</em><sup>[2]<em>T</em></sup><em>d</em><em>Z</em><sup>[2]</sup>. * <em>g</em><sup>[1]′</sup>(<em>z</em><sup>[1]</sup>)</span></p>
<p><span
class="math display"><em>d</em><em>W</em><sup>[1]</sup> = (1/<em>m</em>)<em>d</em><em>Z</em><sup>[1]</sup><em>A</em><sup>[0]<em>T</em></sup></span></p>
<p><span
class="math display"><em>d</em><em>B</em><sup>[1]</sup> = (1/<em>m</em>)<em>Σ</em><em>d</em><em>Z</em><sup>[1]</sup></span></p>
<h3 id="parameter-updates">Parameter updates</h3>
<p><span
class="math display"><em>W</em><sup>[2]</sup> := <em>W</em><sup>[2]</sup> − <em>α</em><em>d</em><em>W</em><sup>[2]</sup></span></p>
<p><span
class="math display"><em>b</em><sup>[2]</sup> := <em>b</em><sup>[2]</sup> − <em>α</em><em>d</em><em>b</em><sup>[2]</sup></span></p>
<p><span
class="math display"><em>W</em><sup>[1]</sup> := <em>W</em><sup>[1]</sup> − <em>α</em><em>d</em><em>W</em><sup>[1]</sup></span></p>
<p><span
class="math display"><em>b</em><sup>[1]</sup> := <em>b</em><sup>[1]</sup> − <em>α</em><em>d</em><em>b</em><sup>[1]</sup></span></p>
<h3 id="vars-and-shapes">Vars and shapes</h3>
<h4 id="forward-prop">Forward prop</h4>
<ul>
<li><span
class="math inline"><em>A</em><sup>[0]</sup> = <em>X</em></span>: 784 x
m</li>
<li><span
class="math inline"><em>Z</em><sup>[1]</sup> ∼ <em>A</em><sup>[1]</sup></span>:
10 x m</li>
<li><span class="math inline"><em>W</em><sup>[1]</sup></span>: 10 x 784
(as <span
class="math inline"><em>W</em><sup>[1]</sup><em>A</em><sup>[0]</sup> ∼ <em>Z</em><sup>[1]</sup></span>)</li>
<li><span class="math inline"><em>B</em><sup>[1]</sup></span>: 10 x
1</li>
<li><span
class="math inline"><em>Z</em><sup>[2]</sup> ∼ <em>A</em><sup>[2]</sup></span>:
10 x m</li>
<li><span class="math inline"><em>W</em><sup>[1]</sup></span>: 10 x 10
(as <span
class="math inline"><em>W</em><sup>[2]</sup><em>A</em><sup>[1]</sup> ∼ <em>Z</em><sup>[2]</sup></span>)</li>
<li><span class="math inline"><em>B</em><sup>[2]</sup></span>: 10 x
1</li>
</ul>
<h4 id="backprop">Backprop</h4>
<ul>
<li><span class="math inline"><em>d</em><em>Z</em><sup>[2]</sup></span>:
10 x m (<span class="math inline"> <em>A</em><sup>[2]</sup></span>)</li>
<li><span class="math inline"><em>d</em><em>W</em><sup>[2]</sup></span>:
10 x 10</li>
<li><span class="math inline"><em>d</em><em>B</em><sup>[2]</sup></span>:
10 x 1</li>
<li><span class="math inline"><em>d</em><em>Z</em><sup>[1]</sup></span>:
10 x m (<span class="math inline"> <em>A</em><sup>[1]</sup></span>)</li>
<li><span class="math inline"><em>d</em><em>W</em><sup>[1]</sup></span>:
10 x 10</li>
<li><span class="math inline"><em>d</em><em>B</em><sup>[1]</sup></span>:
10 x 1</li>
</ul>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_params():</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> np.random.rand(<span class="dv">10</span>, <span class="dv">784</span>) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> np.random.rand(<span class="dv">10</span>, <span class="dv">1</span>) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> np.random.rand(<span class="dv">10</span>, <span class="dv">10</span>) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> np.random.rand(<span class="dv">10</span>, <span class="dv">1</span>) <span class="op">-</span> <span class="fl">0.5</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> W1, b1, W2, b2</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ReLU(Z):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.maximum(Z, <span class="dv">0</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(Z):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.exp(Z) <span class="op">/</span> <span class="bu">sum</span>(np.exp(Z))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_prop(W1, b1, W2, b2, X):</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    Z1 <span class="op">=</span> W1.dot(X) <span class="op">+</span> b1</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    A1 <span class="op">=</span> ReLU(Z1)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    Z2 <span class="op">=</span> W2.dot(A1) <span class="op">+</span> b2</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    A2 <span class="op">=</span> softmax(Z2)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Z1, A1, Z2, A2</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ReLU_deriv(Z):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If Z &gt; 0, return 1, which is the slope of the line.</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Else return 0 (which is still the slope, but recall that values less than 0 are 0)</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Z <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_hot(Y):</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    one_hot_Y <span class="op">=</span> np.zeros((Y.size, Y.<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    one_hot_Y[np.arange(Y.size), Y] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    one_hot_Y <span class="op">=</span> one_hot_Y.T</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> one_hot_Y</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> back_prop(Z1, A1, Z2, A2, W2, X, Y):</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># m = Y.size</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    one_hot_Y <span class="op">=</span> one_hot(Y)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    dZ2 <span class="op">=</span> A2 <span class="op">-</span> one_hot_Y</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    dW2 <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> m <span class="op">*</span> dZ2.dot(A1.T)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    db2 <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> m <span class="op">*</span> np.<span class="bu">sum</span>(dZ2)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    dZ1 <span class="op">=</span> W2.T.dot(dZ2) <span class="op">*</span> ReLU_deriv(Z1)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    dW1 <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> m <span class="op">*</span> dZ1.dot(X.T)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    db1 <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> m <span class="op">*</span> np.<span class="bu">sum</span>(dZ1)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dW1, db1, dW2, db2</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> W1 <span class="op">-</span> alpha <span class="op">*</span> dW1</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> b1 <span class="op">-</span> alpha <span class="op">*</span> db1</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> W2 <span class="op">-</span> alpha <span class="op">*</span> dW2</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> b2 <span class="op">-</span> alpha <span class="op">*</span> db2</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> W1, b1, W2, b2</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_predictions(A2):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.argmax(A2, <span class="dv">0</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_accuracy(predictions, Y):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(predictions, Y)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(predictions <span class="op">==</span> Y) <span class="op">/</span> Y.size</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descnet(X, Y, iterations, alpha):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    W1, b1, W2, b2 <span class="op">=</span> init_params()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        Z1, A1, Z2, A2 <span class="op">=</span> forward_prop(W1, b1, W2, b2, X)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        dW1, db1, dW2, db2 <span class="op">=</span> back_prop(Z1, A1, Z2, A2, W2, X, Y)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        W1, b1, W2, b2 <span class="op">=</span> update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> i <span class="op">==</span> <span class="dv">499</span>:</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Iteration: </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> get_predictions(A2)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Accuracy: </span><span class="sc">{</span>get_accuracy(predictions, Y)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> W1, b1, W2, b2</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>W1, b1, W2, b2 <span class="op">=</span> gradient_descnet(X_train, Y_train, <span class="dv">500</span>, <span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>Iteration: 0
[2 2 2 ... 2 2 8] [8 1 5 ... 4 2 3]
Accuracy: 0.10902898550724638
Iteration: 100
[3 1 0 ... 9 0 3] [8 1 5 ... 4 2 3]
Accuracy: 0.6267101449275362
Iteration: 200
[3 1 2 ... 4 2 3] [8 1 5 ... 4 2 3]
Accuracy: 0.7537971014492754
Iteration: 300
[8 1 3 ... 4 2 3] [8 1 5 ... 4 2 3]
Accuracy: 0.8029855072463769
Iteration: 400
[8 1 3 ... 4 2 3] [8 1 5 ... 4 2 3]
Accuracy: 0.8274782608695652
Iteration: 499
[8 1 3 ... 4 2 3] [8 1 5 ... 4 2 3]
Accuracy: 0.8443768115942029</code></pre>
<p>~85% accuracy on training set</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_predictions(X, W1, b1, W2, b2):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    _, _, _, A2 <span class="op">=</span> forward_prop(W1, b1, W2, b2, X)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> get_predictions(A2)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_prediction(index, W1, b1, W2, b2):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    current_image <span class="op">=</span> X_train[:, index, <span class="va">None</span>]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> make_predictions(X_train[:, index, <span class="va">None</span>], W1, b1, W2, b2)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> Y_train[index]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Prediction: &quot;</span>, prediction)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Label: &quot;</span>, label)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    current_image <span class="op">=</span> current_image.reshape((<span class="dv">28</span>, <span class="dv">28</span>)) <span class="op">*</span> <span class="dv">255</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    plt.gray()</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    plt.imshow(current_image, interpolation<span class="op">=</span><span class="st">&#39;nearest&#39;</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<p>Let’s look at a couple of examples:</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>test_prediction(<span class="dv">0</span>, W1, b1, W2, b2)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>test_prediction(<span class="dv">1</span>, W1, b1, W2, b2)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>test_prediction(<span class="dv">2</span>, W1, b1, W2, b2)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>test_prediction(<span class="dv">3</span>, W1, b1, W2, b2)</span></code></pre></div>
<pre><code>Prediction:  [8]
Label:  8</code></pre>
<p><img
src="https://raw.githubusercontent.com/brombaut/benrombautca/main/src/articles/content/sources_notebooks/images/nn_from_scratch/nn_from_scratch_13_1.png" /></p>
<pre><code>Prediction:  [1]
Label:  1</code></pre>
<p><img
src="https://raw.githubusercontent.com/brombaut/benrombautca/main/src/articles/content/sources_notebooks/images/nn_from_scratch/nn_from_scratch_13_3.png" /></p>
<pre><code>Prediction:  [3]
Label:  5</code></pre>
<p><img
src="https://raw.githubusercontent.com/brombaut/benrombautca/main/src/articles/content/sources_notebooks/images/nn_from_scratch/nn_from_scratch_13_5.png" /></p>
<pre><code>Prediction:  [2]
Label:  8</code></pre>
<p><img
src="https://raw.githubusercontent.com/brombaut/benrombautca/main/src/articles/content/sources_notebooks/images/nn_from_scratch/nn_from_scratch_13_7.png" /></p>
<p>Finally, let’s find the accuracy on the dev set:</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>dev_predictions <span class="op">=</span> make_predictions(X_dev, W1, b1, W2, b2)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>get_accuracy(dev_predictions, Y_dev)</span></code></pre></div>
<pre><code>[4 0 7 7 9 5 6 6 9 4 1 3 3 0 3 3 0 7 0 2 4 5 1 4 7 0 4 9 0 1 7 5 0 9 4 1 1
 2 2 6 1 9 0 0 8 7 0 7 3 1 0 5 7 4 8 9 2 2 2 1 6 7 8 0 4 5 0 2 5 6 7 6 5 7
 4 3 9 4 9 3 7 3 5 6 3 1 5 4 0 8 0 0 0 0 4 8 4 7 5 6 5 5 3 4 9 1 9 2 3 4 4
 1 0 1 0 2 8 8 8 9 5 5 4 1 8 0 2 2 3 9 4 0 0 9 5 4 5 4 4 4 6 2 5 7 0 1 4 8
 3 6 4 3 8 6 1 4 8 7 1 2 7 3 6 2 1 4 6 8 1 9 9 3 4 4 3 9 6 7 6 4 7 6 2 3 3
 6 4 4 3 3 9 4 1 6 5 1 3 0 2 2 6 2 1 4 2 1 9 5 3 4 6 5 2 7 1 6 6 1 3 1 4 2
 5 2 1 8 7 1 6 1 0 3 9 7 0 6 3 2 9 8 5 4 7 0 1 7 8 0 5 1 8 1 7 9 8 9 5 3 2
 4 3 3 1 0 5 2 2 7 0 9 0 9 1 9 1 2 0 1 1 9 7 9 8 0 0 7 3 9 6 3 6 5 8 4 0 9
 1 2 4 8 0 5 8 8 2 1 5 3 9 9 5 7 7 0 3 8 9 9 3 7 2 8 8 8 2 4 5 9 6 4 5 1 8
 9 5 2 2 7 9 7 8 8 8 7 6 2 0 3 0 8 8 6 0 0 3 3 9 1 9 8 2 4 5 4 9 8 5 0 7 0
 7 7 1 7 6 2 3 0 2 3 5 8 7 7 5 7 7 1 4 2 7 6 4 7 7 6 1 2 3 1 4 3 6 6 7 0 7
 5 5 6 2 4 7 5 4 8 6 2 9 8 3 2 7 9 0 5 6 2 9 7 6 2 8 8 2 4 3 3 1 7 1 9 0 1
 8 1 4 7 9 8 1 4 1 4 0 8 6 8 6 3 9 0 6 7 1 0 3 0 1 6 9 6 8 1 4 5 9 1 0 1 7
 1 1 8 0 0 6 3 8 8 3 1 9 7 8 3 2 1 6 3 3 7 8 8 8 3 2 4 4 3 4 1 7 6 7 0 2 2
 6 5 8 1 3 1 0 4 3 0 7 9 3 1 0 7 8 6 6 1 2 0 1 0 6 4 1 4 8 8 5 5 1 2 4 1 6
 7 2 8 2 1 7 5 1 0 3 5 8 4 3 4 2 0 3 6 5 9 2 6 9 2 9 6 6 4 7 4 4 9 7 6 0 7
 7 6 8 7 4 3 4 1 9 7 6 1 3 1 0 9 0 5 7 9 0 3 6 6 1 0 2 1 1 0 1 3 6 0 2 3 3
 8 5 1 8 6 4 7 8 6 6 2 1 0 1 4 1 0 0 5 9 2 8 5 8 4 0 8 7 7 4 7 3 2 6 1 3 4
 6 8 3 7 3 0 0 8 8 5 0 1 9 0 7 6 6 7 6 2 6 0 2 3 8 6 5 3 3 0 9 8 1 5 4 1 5
 0 9 7 3 4 8 1 1 4 9 9 1 6 2 2 8 1 1 1 6 6 6 0 9 9 9 0 4 0 8 5 1 7 6 3 1 4
 7 6 0 7 1 0 5 6 2 1 7 9 8 7 4 7 9 9 5 9 6 4 0 2 6 9 8 8 5 2 0 4 3 7 4 1 7
 9 3 5 8 5 4 1 6 1 9 2 7 3 1 1 9 4 3 7 3 0 3 2 1 5 0 6 2 6 2 4 6 7 7 1 5 9
 4 3 9 7 7 9 7 1 6 1 8 8 8 0 8 9 5 2 4 7 4 9 8 6 1 9 3 9 9 0 2 9 5 8 7 9 5
 4 1 2 5 8 1 8 1 3 8 1 8 9 2 6 2 3 8 2 7 2 3 5 5 0 6 9 2 7 7 5 0 0 5 0 6 9
 1 6 3 4 0 6 1 2 2 3 9 1 1 1 3 6 4 1 7 8 8 5 9 7 3 9 2 4 9 3 6 7 6 6 4 5 6
 7 9 9 2 0 2 9 3 0 5 6 3 8 8 0 6 6 7 8 9 1 2 0 2 1 8 2 0 7 5 4 0 6 5 1 0 5
 0 9 4 6 4 2 0 4 4 2 1 9 9 0 3 2 3 5 0 4 0 2 4 5 1 2 5 3 9 4 2 7 5 6 3 8 2
 5] [7 0 7 7 9 3 6 6 9 7 1 3 3 0 3 8 0 7 0 2 4 2 1 4 7 0 4 9 0 1 7 5 2 4 4 7 1
 5 5 6 1 9 0 0 4 7 0 7 3 1 0 7 7 4 8 9 2 2 6 1 6 7 8 0 8 5 0 2 5 6 9 6 3 4
 4 3 8 4 9 3 7 3 5 6 3 1 5 4 0 8 4 0 0 0 4 5 4 7 8 6 5 6 7 4 4 1 9 2 9 4 4
 1 0 1 0 2 8 8 8 9 5 5 9 1 8 0 2 2 3 9 4 0 0 9 5 9 5 4 4 9 6 2 5 7 5 1 4 8
 3 5 4 3 4 6 1 9 8 7 1 2 7 3 6 3 1 4 6 8 1 9 9 3 4 9 3 9 6 7 6 4 7 3 2 3 3
 6 4 4 2 3 9 4 1 6 5 8 3 0 2 2 6 2 1 4 2 1 9 0 3 4 6 5 2 7 1 6 6 1 3 1 4 2
 5 2 1 8 7 1 6 1 3 5 9 7 0 6 3 2 9 5 5 4 7 0 1 7 8 0 5 1 8 1 7 9 8 9 2 9 0
 9 3 2 1 0 5 2 2 7 0 9 0 9 1 9 1 9 0 1 1 3 7 2 5 0 0 9 5 9 6 3 6 5 9 4 0 9
 6 2 4 8 0 5 8 8 2 1 0 3 9 8 5 3 7 0 3 8 9 8 3 7 2 8 3 1 2 4 5 9 6 4 5 1 8
 9 5 2 7 9 9 7 5 5 8 1 0 2 0 3 0 4 8 6 0 0 3 3 9 1 9 5 2 4 7 4 7 8 5 0 9 0
 7 7 1 7 6 5 3 0 2 3 6 8 7 7 5 7 7 6 4 2 7 6 4 7 7 6 1 2 3 5 4 3 6 6 7 0 7
 5 5 6 2 4 2 5 4 3 6 2 4 8 0 6 7 9 0 5 6 2 9 7 6 7 9 8 3 4 3 8 1 7 1 9 0 1
 8 1 4 7 9 8 1 4 1 4 0 8 6 8 6 3 9 0 6 7 1 0 3 0 1 2 7 6 5 1 4 5 9 1 0 1 7
 1 1 8 5 0 6 3 8 8 7 1 9 2 8 0 2 1 6 3 8 7 8 8 8 3 2 4 4 3 4 1 7 0 7 0 2 0
 2 5 8 1 3 1 0 4 3 0 7 9 3 1 0 7 8 6 6 1 2 0 1 0 5 4 7 4 3 8 5 5 1 1 4 1 6
 7 2 5 2 1 7 0 1 0 3 5 8 4 3 3 2 0 3 6 5 9 2 6 7 2 9 6 5 4 7 5 4 4 7 6 0 7
 7 6 8 7 4 3 6 1 9 7 6 1 3 1 0 9 0 5 9 7 0 3 2 4 2 0 2 1 1 0 1 7 6 0 2 3 3
 8 5 1 8 6 4 3 8 6 6 2 1 0 1 9 1 0 0 5 9 2 8 5 9 4 0 9 7 7 4 2 3 2 6 1 3 4
 6 8 3 7 3 0 0 8 8 5 0 1 8 0 7 6 6 7 6 2 6 0 2 3 8 6 5 3 3 0 9 8 1 9 4 1 5
 0 9 7 3 4 8 1 1 4 9 9 1 6 2 2 8 1 7 1 6 5 6 0 7 9 9 0 4 0 5 6 1 7 6 3 1 4
 7 6 0 7 1 0 8 6 2 1 7 9 8 7 4 7 9 4 5 4 6 7 0 2 6 4 8 3 3 2 0 4 3 7 4 1 7
 9 3 5 8 5 4 1 6 1 0 2 7 3 1 1 9 4 3 7 3 0 3 2 1 5 2 6 6 6 8 4 6 7 7 1 5 9
 9 2 9 7 7 9 9 1 6 1 8 8 8 6 8 9 5 2 4 7 4 9 1 6 1 9 3 9 9 0 2 9 9 8 7 9 5
 4 1 1 5 8 1 8 1 3 8 1 1 9 2 6 2 3 8 7 9 2 3 3 5 0 2 0 2 7 7 5 0 0 5 0 6 4
 1 2 3 4 0 6 1 0 2 3 9 1 1 1 2 6 4 1 7 9 2 5 8 7 3 9 2 4 9 8 2 7 6 6 4 5 6
 7 4 2 2 0 2 9 2 0 5 6 3 5 8 9 6 6 7 8 9 1 2 0 3 1 8 2 0 7 5 4 0 6 5 1 0 5
 0 9 4 6 4 2 0 4 4 2 8 9 7 7 3 2 3 5 0 4 0 2 4 5 1 2 5 3 9 4 2 9 5 6 3 5 2
 5]





0.831</code></pre>
<p>Still 83% accuracy, so our model generalized from the training data
pretty well.</p>
<p>References - <a
href="https://www.youtube.com/watch?v=w8yWXqWQYmU&amp;ab_channel=SamsonZhang">YouTube
Video</a> - <a
href="https://www.kaggle.com/code/wwsalmon/simple-mnist-nn-from-scratch-numpy-no-tf-keras/notebook">Kaggle
Notbook</a></p>
